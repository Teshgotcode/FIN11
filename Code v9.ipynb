{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44071e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT 0: IMPORT LIBRARIES\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from linearmodels.panel import PanelOLS\n",
    "from stargazer.stargazer import Stargazer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT 1: SETUP - DEFINE CONSTANTS AND TICKERS\n",
    "\n",
    "TICKERS = {\n",
    "    \"Large Cap\": [\n",
    "        'EQNR.OL', 'DNB.OL', 'KOG.OL', 'MOWI.OL', 'TEL.OL', 'NHY.OL', 'AKRBP.OL',\n",
    "        'ORK.OL', 'STB.OL', 'YAR.OL', 'SUBC.OL', 'GJF.OL', 'SALM.OL', 'TGS.OL',\n",
    "        'TOM.OL', 'VAR.OL', 'NEL.OL', 'FRO.OL', 'BWLPG.OL', 'HAUTO.OL',\n",
    "        'NOD.OL', 'WAWI.OL', 'NAS.OL', 'BAKKA.OL', 'WWI.OL', 'AFK.OL',\n",
    "        'AUSS.OL', 'SCATC.OL', 'MPCC.OL', 'HAFNI.OL'\n",
    "    ],\n",
    "    \"Mid Cap\": [\n",
    "        'AKER.OL', 'LSG.OL', 'KIT.OL', 'AKSO.OL', 'PARB.OL', 'BONHR.OL',\n",
    "        'BOUV.OL', 'DNO.OL', 'ENTRA.OL', 'FLNG.OL', 'MING.OL', 'NAPA.OL',\n",
    "        'NORBT.OL', 'OLT.OL', 'PCIB.OL', 'REACH.OL', 'WSTEP.OL', 'KOA.OL',\n",
    "        'HSPG.OL', 'SOFF.OL', 'ABG.OL', 'BGBIO.OL', 'EMGS.OL', 'EXTX.OL',\n",
    "        'HAVI.OL', 'HELG.OL', 'IDEX.OL', 'JIN.OL', 'MULTI.OL', 'NYKD.OL'\n",
    "    ],\n",
    "    \"Small Cap\": [\n",
    "        'QEC.OL', 'RECSI.OL', 'SPOL.OL', 'AZT.OL', 'KID.OL', 'SATS.OL',\n",
    "        'AURG.OL', 'PEN.OL', 'LINK.OL', 'PROT.OL', 'IOX.OL', 'ACC.OL',\n",
    "        'TECH.OL', 'CONTX.OL', 'NONG.OL', 'BEWI.OL', 'ELO.OL', 'GSF.OL',\n",
    "        'PRS.OL', 'AIRX.OL', 'OBSRV.OL', 'HUNT.OL', 'AKVA.OL', 'HEX.OL',\n",
    "        'SOFTX.OL', 'ASA.OL', 'NORTH.OL', 'CAPSL.OL', 'LYTIX.OL', 'VOW.OL'\n",
    "    ]\n",
    "}\n",
    "\n",
    "START_DATE = \"2014-01-01\"\n",
    "END_DATE = \"2024-12-31\"\n",
    "OUTPUT_CSV = \"oslo_bors_labelled_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT 1.1: CORWIN-SCHULTZ AND ABDI-RANALDO SPREAD ESTIMATORS\n",
    "def corwin_schultz_spread(group):\n",
    "    \"\"\"\n",
    "    Corwin-Schultz (2012) High-Low spread estimator.\n",
    "    This function calculates a daily spread estimate.\n",
    "    \n",
    "    Reference: Corwin, S. A., & Schultz, P. (2012). A simple way to estimate \n",
    "    bid-ask spreads from daily high and low prices. The Journal of Finance, 67(2), 719-760.\n",
    "    \"\"\"\n",
    "    group = group.sort_values('Date')\n",
    "    \n",
    "    high = group['High'].values\n",
    "    low = group['Low'].values\n",
    "    \n",
    "    spreads = []\n",
    "    negative_count = 0\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        if i == 0:\n",
    "            spreads.append(np.nan)\n",
    "        else:\n",
    "            h0, l0 = high[i], low[i]\n",
    "            h1, l1 = high[i-1], low[i-1]\n",
    "            \n",
    "            if h0 > 0 and l0 > 0 and h1 > 0 and l1 > 0:\n",
    "                beta = (np.log(h0/l0))**2 + (np.log(h1/l1))**2\n",
    "                h_max = max(h0, h1)\n",
    "                l_min = min(l0, l1)\n",
    "                gamma = (np.log(h_max/l_min))**2\n",
    "                \n",
    "                k = (3 - 2*np.sqrt(2))\n",
    "                alpha = (np.sqrt(2*beta) - np.sqrt(beta)) / k - np.sqrt(gamma / k)\n",
    "                \n",
    "                spread = 2 * (np.exp(alpha) - 1) / (1 + np.exp(alpha))\n",
    "                \n",
    "                if spread >= 0:\n",
    "                    spreads.append(spread)\n",
    "                else:\n",
    "                    spreads.append(np.nan)\n",
    "                    negative_count += 1\n",
    "            else:\n",
    "                spreads.append(np.nan)\n",
    "    \n",
    "    if negative_count > 0:\n",
    "        ticker = group['Ticker'].iloc[0] if 'Ticker' in group.columns else 'Unknown'\n",
    "        # print(f\"  Warning: {ticker} had {negative_count} negative Corwin-Schultz estimates (set to NaN)\")\n",
    "    \n",
    "    group['Spread'] = spreads\n",
    "    return group\n",
    "\n",
    "\n",
    "def abdi_ranaldo_spread(group):\n",
    "    \"\"\"\n",
    "    Calculates the NORMALIZED Abdi and Ranaldo (2017) \"BAR\" spread estimator.\n",
    "    This version converts the absolute spread (in currency) to a relative \n",
    "    spread (as a percentage of the price), making it comparable across stocks.\n",
    "    \"\"\"\n",
    "    group = group.sort_values('Date')\n",
    "\n",
    "    delta_p_t = group['Close'].diff()\n",
    "    delta_p_t_minus_1 = delta_p_t.shift(1)\n",
    "\n",
    "    if delta_p_t.count() < 2:\n",
    "        return pd.Series(np.nan, index=group.index, name='Spread')\n",
    "\n",
    "    cov_term = (delta_p_t * delta_p_t_minus_1)\n",
    "    \n",
    "    # Calculate the absolute spread (in currency units)\n",
    "    absolute_spreads = 2 * np.sqrt(np.maximum(0, -cov_term))\n",
    "    \n",
    "    # NORMALIZATION STEP\n",
    "    # To get a relative spread, divide by the average of today's and yesterday's close price.\n",
    "    # Rolling window to get the average price at each point in time.\n",
    "    avg_price = group['Close'].rolling(window=2, min_periods=1).mean()\n",
    "    \n",
    "    # Calculate the relative spread. Use .values to avoid index alignment issues.\n",
    "    relative_spreads = absolute_spreads / avg_price.values\n",
    "    \n",
    "    # Assign the comparable, relative spreads to the DataFrame\n",
    "    group['Spread'] = relative_spreads\n",
    "    return group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2522e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT 1.2: ADD PERIOD LABELS FOR HOLIDAY ANALYSIS\n",
    "def add_period_labels(df):\n",
    "    \"\"\"\n",
    "    Adds period labels for holiday analysis.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    years = range(df['Date'].dt.year.min(), df['Date'].dt.year.max() + 1)\n",
    "    norway_holidays = holidays.Norway(years=years)\n",
    "    \n",
    "    df['week'] = df['Date'].dt.isocalendar().week.astype(int)\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['period_label'] = 'control_year'\n",
    "\n",
    "    for yr in years:\n",
    "        christmas_ref_start = pd.Timestamp(f'{yr}-12-15')\n",
    "        christmas_ref_end = pd.Timestamp(f'{yr}-12-31')\n",
    "        christmas_days = pd.bdate_range(start=christmas_ref_start, end=christmas_ref_end, freq='C', holidays=list(norway_holidays.keys()), weekmask='Mon Tue Wed Thu Fri')\n",
    "        \n",
    "        if len(christmas_days) > 0:\n",
    "            pre_christmas = pd.bdate_range(end=christmas_days[0] - pd.Timedelta(days=1), periods=5, freq='C', holidays=list(norway_holidays.keys()), weekmask='Mon Tue Wed Thu Fri')\n",
    "            try:\n",
    "                post_christmas_start = pd.Timestamp(f'{yr+1}-01-02')\n",
    "                post_christmas = pd.bdate_range(start=post_christmas_start, periods=5, freq='C', holidays=list(norway_holidays.keys()), weekmask='Mon Tue Wed Thu Fri')\n",
    "            except:\n",
    "                post_christmas = pd.bdate_range(start=christmas_days[-1] + pd.Timedelta(days=1), periods=5, freq='C', holidays=list(norway_holidays.keys()), weekmask='Mon Tue Wed Thu Fri')\n",
    "            \n",
    "            df.loc[df['Date'].isin(pre_christmas), 'period_label'] = 'pre_christmas'\n",
    "            df.loc[df['Date'].isin(christmas_days), 'period_label'] = 'christmas'\n",
    "            df.loc[df['Date'].isin(post_christmas), 'period_label'] = 'post_christmas'\n",
    "\n",
    "    for yr in years:\n",
    "        easter_days = [d for d, h in norway_holidays.items() if ('Påske' in h or h in ['Skjærtorsdag', 'Langfredag']) and d.year == yr]\n",
    "        \n",
    "        if easter_days:\n",
    "            easter_start = min(easter_days)\n",
    "            easter_end = max(easter_days)\n",
    "            pre_easter = pd.bdate_range(end=easter_start - pd.Timedelta(days=1), periods=5, freq='C', holidays=list(norway_holidays.keys()), weekmask='Mon Tue Wed Thu Fri')\n",
    "            post_easter = pd.bdate_range(start=easter_end + pd.Timedelta(days=1), periods=5, freq='C', holidays=list(norway_holidays.keys()), weekmask='Mon Tue Wed Thu Fri')\n",
    "            df.loc[df['Date'].isin(pre_easter), 'period_label'] = 'pre_easter'\n",
    "            df.loc[df['Date'].isin(post_easter), 'period_label'] = 'post_easter'\n",
    "\n",
    "    df.loc[df['week'].between(28, 30), 'period_label'] = 'summer_holiday'\n",
    "    df.loc[(df['month'].between(6, 8)) & (~df['week'].between(28, 30)), 'period_label'] = 'summer_excl_holiday'\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dba716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT 1.3: CHOOSE SPREAD ESTIMATOR (Simplified)\n",
    "user_input = input(\"Which spread estimator do you want to use? (Enter 'CS' or 'AR'): \")\n",
    "\n",
    "# Determine the spread method based on user input\n",
    "if user_input.upper() == 'AR':\n",
    "    METHOD_CHOICE = 'AR'\n",
    "    SPREAD_METHOD_NAME = 'Abdi & Ranaldo (2017) Spread'\n",
    "else:\n",
    "    METHOD_CHOICE = 'CS'\n",
    "    SPREAD_METHOD_NAME = 'Corwin-Schultz (2012) Spread'\n",
    "\n",
    "print(f\"The analysis will use the '{SPREAD_METHOD_NAME}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT 1.4: MAIN DATA PROCESSING FUNCTION\n",
    "def main():\n",
    "    print(\"-\" * 80)\n",
    "    print(\"OSLO BØRS HOLIDAY EFFECTS ANALYSIS - DATA PREPARATION\")\n",
    "    # Use f-string to print the full name\n",
    "    print(f\"Using spread estimator: {SPREAD_METHOD_NAME}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    all_tickers = [ticker for sublist in TICKERS.values() for ticker in sublist]\n",
    "    print(f\"\\nDownloading data for {len(all_tickers)} tickers...\")\n",
    "    print(f\"Date range: {START_DATE} to {END_DATE}\")\n",
    "    \n",
    "    raw_data = yf.download(all_tickers, start=START_DATE, end=END_DATE, progress=True, auto_adjust=True)\n",
    "\n",
    "    if raw_data.empty:\n",
    "        print(\"ERROR: No data downloaded\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"TRANSFORMING DATA STRUCTURE\")\n",
    "    print(\"-\"*80)\n",
    "    df = raw_data.stack(future_stack=True).reset_index()\n",
    "    df = df.rename(columns={'level_1': 'Ticker'})\n",
    "    \n",
    "    ticker_to_cap = {ticker: cap for cap, tickers in TICKERS.items() for ticker in tickers}\n",
    "    df['Cap_Group'] = df['Ticker'].map(ticker_to_cap)\n",
    "    \n",
    "    initial_len = len(df)\n",
    "    df.dropna(subset=['Open', 'High', 'Low', 'Close', 'Volume', 'Cap_Group'], inplace=True)\n",
    "    print(f\"Removed {initial_len - len(df):,} rows with missing price/volume data\")\n",
    "\n",
    "    # Spread Calculation\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    if METHOD_CHOICE == 'CS':\n",
    "        print(\"CALCULATING CORWIN-SCHULTZ SPREADS (DAILY ESTIMATE)\")\n",
    "        df = df.groupby('Ticker', group_keys=False).apply(corwin_schultz_spread)\n",
    "    elif METHOD_CHOICE == 'AR':\n",
    "        print(\"CALCULATING ABDI & RANALDO (2017) 'BAR' SPREADS\")\n",
    "        df = df.groupby('Ticker', group_keys=False).apply(abdi_ranaldo_spread)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method choice. Please choose 'CS' or 'AR'.\")\n",
    "    print(\"Spread calculation complete.\")\n",
    "\n",
    "    # Data Quality Check and Cleaning\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"DATA QUALITY CHECK FOR METHOD: {METHOD_CHOICE}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    total_spreads = len(df[df.index > 0]) # Avoid counting first NaN\n",
    "    valid_spreads = df['Spread'].notna().sum()\n",
    "    invalid_spreads = total_spreads - valid_spreads\n",
    "    \n",
    "    print(f\"\\nCalculation summary for '{METHOD_CHOICE}':\")\n",
    "    print(f\"  Total observations:     {total_spreads:,}\")\n",
    "    print(f\"  Valid spreads:          {valid_spreads:,} ({valid_spreads/total_spreads*100:.2f}%)\")\n",
    "    print(f\"  Invalid/missing:        {invalid_spreads:,} ({invalid_spreads/total_spreads*100:.2f}%)\")\n",
    "    \n",
    "    spread_before = len(df)\n",
    "    df = df.dropna(subset=['Spread'])\n",
    "    print(f\"\\nRemoved {spread_before - len(df):,} rows with missing spreads\")\n",
    "\n",
    "    # Roll's Spread Calculation\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"CALCULATING ROLL'S SPREADS (PER-STOCK ROBUSTNESS CHECK)\")\n",
    "    print(\"-\" * 80)\n",
    "    roll_spreads = df.groupby('Ticker').apply(get_roll_spread)\n",
    "    df['RollsSpread'] = df['Ticker'].map(roll_spreads)\n",
    "    \n",
    "    valid_rolls = roll_spreads.notna().sum()\n",
    "    print(f\"Roll's spread calculation summary:\")\n",
    "    print(f\"  Tickers with valid spread: {valid_rolls} / {df['Ticker'].nunique()}\")\n",
    "    print(f\"  Average calculated Roll's spread: {roll_spreads.mean():.6f}\")\n",
    "\n",
    "    # Period Labeling and Final Export\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"ADDING PERIOD LABELS\")\n",
    "    print(\"-\"*80)\n",
    "    df = add_period_labels(df)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"FINAL DATA EXPORT\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    final_cols = ['Date', 'Ticker', 'Cap_Group', 'Open', 'High', 'Low', 'Close', 'Volume', 'Spread', 'RollsSpread', 'period_label']\n",
    "    df_final = df[[col for col in final_cols if col in df.columns]]\n",
    "    df_final.to_csv(OUTPUT_CSV, index=False)\n",
    "    \n",
    "    print(f\"Data saved to: {OUTPUT_CSV}\")\n",
    "    print(f\"Total observations: {len(df_final):,}\")\n",
    "    \n",
    "    print(f\"\\n'{METHOD_CHOICE}' Spread ('Spread') statistics:\")\n",
    "    print(f\"  Mean:   {df_final['Spread'].mean():.6f}\")\n",
    "    \n",
    "    print(f\"\\nRoll's Spread ('RollsSpread') statistics:\")\n",
    "    print(f\"  Mean:   {df_final['RollsSpread'].mean():.6f}\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT 2: DESCRIPTIVE STATISTICS AND VISUALIZATION (OPTIMIZED)\n",
    "\n",
    "df = pd.read_csv('oslo_bors_labelled_data.csv', parse_dates=['Date'])\n",
    "\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(\"DESCRIPTIVE STATISTICS AND VISUALIZATION\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Dataset overview\n",
    "print(f\"\\nTotal observations: {len(df):,}\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "print(f\"Unique tickers: {df['Ticker'].nunique()}\")\n",
    "print(f\"Trading days: {df['Date'].nunique():,}\")\n",
    "\n",
    "# Summary by cap group\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SUMMARY BY CAP GROUP\")\n",
    "print(\"-\"*80)\n",
    "summary_cap = df.groupby('Cap_Group').agg({\n",
    "    'Spread': ['mean', 'median', 'std'],\n",
    "    'Volume': ['mean', 'median'],\n",
    "    'Ticker': 'nunique'\n",
    "}).round(6)\n",
    "summary_cap.columns = ['Spread_Mean', 'Spread_Median', 'Spread_Std', 'Volume_Mean', 'Volume_Median', 'N_Stocks']\n",
    "print(summary_cap)\n",
    "\n",
    "# Summary by period\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SUMMARY BY PERIOD\")\n",
    "print(\"-\"*80)\n",
    "summary_period = df.groupby('period_label').agg({\n",
    "    'Spread': ['mean', 'median'],\n",
    "    'Volume': ['mean', 'median'],\n",
    "    'Date': 'count'\n",
    "}).round(6)\n",
    "summary_period.columns = ['Spread_Mean', 'Spread_Median', 'Volume_Mean', 'Volume_Median', 'N_Obs']\n",
    "print(summary_period)\n",
    "\n",
    "# Calculate percentage changes vs control\n",
    "control_spread = summary_period.loc['control_year', 'Spread_Mean']\n",
    "control_volume = summary_period.loc['control_year', 'Volume_Mean']\n",
    "summary_period['Spread_Change_%'] = ((summary_period['Spread_Mean'] - control_spread) / control_spread * 100).round(2)\n",
    "summary_period['Volume_Change_%'] = ((summary_period['Volume_Mean'] - control_volume) / control_volume * 100).round(2)\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"CHANGES VS CONTROL PERIOD\")\n",
    "print(\"-\"*80)\n",
    "print(summary_period[['Spread_Mean', 'Spread_Change_%', 'Volume_Mean', 'Volume_Change_%']])\n",
    "\n",
    "summary_cap.to_csv('output/summary_by_cap.csv')\n",
    "summary_period.to_csv('output/summary_by_period.csv')\n",
    "\n",
    "# FIGURE 1: CHRISTMAS & EASTER ANALYSIS\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"GENERATING FIGURE 1: CHRISTMAS & EASTER\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "christmas_easter_periods = ['control_year', 'pre_easter', 'post_easter',\n",
    "                            'pre_christmas', 'christmas', 'post_christmas']\n",
    "df_ce = df[df['period_label'].isin(christmas_easter_periods)].copy()\n",
    "df_ce['period_label'] = pd.Categorical(df_ce['period_label'],\n",
    "                                       categories=christmas_easter_periods,\n",
    "                                       ordered=True)\n",
    "\n",
    "# Figure 1A: Spread (added confidence intervals)\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.pointplot(x='period_label', y='Spread', hue='Cap_Group', data=df_ce,\n",
    "             hue_order=['Large Cap', 'Mid Cap', 'Small Cap'],\n",
    "             dodge=True,\n",
    "             palette='viridis',\n",
    "             errorbar='ci',\n",
    "             capsize=0.1)\n",
    "plt.title(f'Figure 1A: Mean Spread (Christmas & Easter Periods) | {SPREAD_METHOD_NAME}', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('Period', fontsize=14)\n",
    "plt.ylabel('Mean Spread', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Cap Group', title_fontsize=12, fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/Figure_1A_CE_Spread.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: Figure_1A_CE_Spread.png\")\n",
    "\n",
    "# Figure 1B: Volume\n",
    "volume_ce = df_ce.groupby(['period_label', 'Cap_Group'], observed=False)['Volume'].mean().reset_index()\n",
    "volume_ce['Volume_millions'] = volume_ce['Volume'] / 1e6\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='period_label', y='Volume_millions', hue='Cap_Group', data=volume_ce,\n",
    "           hue_order=['Large Cap', 'Mid Cap', 'Small Cap'],\n",
    "           palette='magma',\n",
    "           errorbar='ci')\n",
    "plt.title(f'Figure 1B: Mean Daily Volume (Christmas & Easter Periods) | {SPREAD_METHOD_NAME}', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('Period', fontsize=14)\n",
    "plt.ylabel('Mean Volume (millions)', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Cap Group', title_fontsize=12, fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/Figure_1B_CE_Volume.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: Figure_1B_CE_Volume.png\")\n",
    "\n",
    "# FIGURE 2: SUMMER ANALYSIS\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"GENERATING FIGURE 2: SUMMER HOLIDAY\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "summer_periods = ['control_year', 'summer_excl_holiday', 'summer_holiday']\n",
    "df_summer = df[df['period_label'].isin(summer_periods)].copy()\n",
    "df_summer['period_label'] = pd.Categorical(df_summer['period_label'],\n",
    "                                           categories=summer_periods,\n",
    "                                           ordered=True)\n",
    "\n",
    "# Figure 2A: Spread\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.pointplot(x='period_label', y='Spread', hue='Cap_Group', data=df_summer,\n",
    "             hue_order=['Large Cap', 'Mid Cap', 'Small Cap'],\n",
    "             dodge=True,\n",
    "             palette='viridis',\n",
    "             errorbar='ci',\n",
    "             capsize=0.1)\n",
    "plt.title(f'Figure 2A: Mean Spread (Summer Holiday) | {SPREAD_METHOD_NAME}', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('Period', fontsize=14)\n",
    "plt.ylabel('Mean Spread', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Cap Group', title_fontsize=12, fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/Figure_2A_Summer_Spread.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: Figure_2A_Summer_Spread.png\")\n",
    "\n",
    "# Figure 2B: Volume\n",
    "volume_summer = df_summer.groupby(['period_label', 'Cap_Group'], observed=False)['Volume'].mean().reset_index()\n",
    "volume_summer['Volume_millions'] = volume_summer['Volume'] / 1e6\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.barplot(x='period_label', y='Volume_millions', hue='Cap_Group', data=volume_summer,\n",
    "           hue_order=['Large Cap', 'Mid Cap', 'Small Cap'],\n",
    "           palette='magma',\n",
    "           errorbar='ci')\n",
    "plt.title(f'Figure 2B: Mean Daily Volume (Summer Holiday) | {SPREAD_METHOD_NAME}', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('Period', fontsize=14)\n",
    "plt.ylabel('Mean Volume (millions)', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Cap Group', title_fontsize=12, fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/Figure_2B_Summer_Volume.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: Figure_2B_Summer_Volume.png\")\n",
    "\n",
    "# FIGURE 3: P-VALUE HEATMAPS WITH MULTIPLE TESTING CORRECTION\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"GENERATING FIGURE 3: P-VALUE HEATMAPS (WITH MULTIPLE CORRECTIONS)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Import multiple testing correction\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "p_values_spread = {}\n",
    "p_values_volume = {}\n",
    "\n",
    "# Collect all raw p-values for correction\n",
    "all_p_spread = []\n",
    "all_p_volume = []\n",
    "test_info = []  # To keep track of which test corresponds to which p-value\n",
    "\n",
    "for group in ['Large Cap', 'Mid Cap', 'Small Cap']:\n",
    "    p_values_spread[group] = {}\n",
    "    p_values_volume[group] = {}\n",
    "    \n",
    "    control = df_ce[(df_ce['period_label'] == 'control_year') & (df_ce['Cap_Group'] == group)]\n",
    "    \n",
    "    for period in [p for p in christmas_easter_periods if p != 'control_year']:\n",
    "        event = df_ce[(df_ce['period_label'] == period) & (df_ce['Cap_Group'] == group)]\n",
    "        \n",
    "        if len(event) > 1 and len(control) > 1:\n",
    "            _, p_spread = ttest_ind(event['Spread'].dropna(),\n",
    "                                   control['Spread'].dropna(),\n",
    "                                   equal_var=False)\n",
    "            _, p_volume = ttest_ind(event['Volume'].dropna(),\n",
    "                                   control['Volume'].dropna(),\n",
    "                                   equal_var=False)\n",
    "            \n",
    "            all_p_spread.append(p_spread)\n",
    "            all_p_volume.append(p_volume)\n",
    "            test_info.append((group, period))\n",
    "            \n",
    "            p_values_spread[group][period] = p_spread\n",
    "            p_values_volume[group][period] = p_volume\n",
    "\n",
    "# Multiple Testing Correction\n",
    "\n",
    "# Method 1: Bonferroni Correction (Conservative)\n",
    "print(\"\\n--- Applying Bonferroni Correction ---\")\n",
    "print(f'Total tests performed: {len(all_p_spread)}')\n",
    "print(f'Bonferroni-corrected alpha level: {0.05 / len(all_p_spread):.5f}\\n')\n",
    "\n",
    "reject_spread_bonf, pvals_corrected_spread_bonf, _, _ = multipletests(\n",
    "    all_p_spread, alpha=0.05, method='bonferroni'\n",
    ")\n",
    "reject_volume_bonf, pvals_corrected_volume_bonf, _, _ = multipletests(\n",
    "    all_p_volume, alpha=0.05, method='bonferroni'\n",
    ")\n",
    "\n",
    "# Method 2: Benjamini-Hochberg (FDR) Correction (Less Conservative)\n",
    "print(\"--- Applying Benjamini-Hochberg (FDR) Correction ---\")\n",
    "reject_spread_fdr, pvals_corrected_spread_fdr, _, _ = multipletests(\n",
    "    all_p_spread, alpha=0.05, method='fdr_bh'\n",
    ")\n",
    "reject_volume_fdr, pvals_corrected_volume_fdr, _, _ = multipletests(\n",
    "    all_p_volume, alpha=0.05, method='fdr_bh'\n",
    ")\n",
    "print(\"FDR correction applied.\\n\")\n",
    "\n",
    "# Create DataFrames for Heatmaps and Comparison\n",
    "\n",
    "# Create DataFrame for raw p-values (for heatmap annotation)\n",
    "p_values_spread_df = pd.DataFrame(p_values_spread).T\n",
    "p_values_volume_df = pd.DataFrame(p_values_volume).T\n",
    "\n",
    "# Create DataFrames for corrected p-values\n",
    "p_values_corrected_df_spread_bonf = pd.DataFrame(index=p_values_spread_df.index, columns=p_values_spread_df.columns)\n",
    "p_values_corrected_df_volume_bonf = pd.DataFrame(index=p_values_volume_df.index, columns=p_values_volume_df.columns)\n",
    "p_values_corrected_df_spread_fdr = pd.DataFrame(index=p_values_spread_df.index, columns=p_values_spread_df.columns)\n",
    "p_values_corrected_df_volume_fdr = pd.DataFrame(index=p_values_volume_df.index, columns=p_values_volume_df.columns)\n",
    "\n",
    "# Populate corrected p-value DataFrames\n",
    "for i, (group, period) in enumerate(test_info):\n",
    "    p_values_corrected_df_spread_bonf.loc[group, period] = pvals_corrected_spread_bonf[i]\n",
    "    p_values_corrected_df_volume_bonf.loc[group, period] = pvals_corrected_volume_bonf[i]\n",
    "    p_values_corrected_df_spread_fdr.loc[group, period] = pvals_corrected_spread_fdr[i]\n",
    "    p_values_corrected_df_volume_fdr.loc[group, period] = pvals_corrected_volume_fdr[i]\n",
    "\n",
    "# --- Print Comparison Tables ---\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"COMPARISON OF CORRECTED P-VALUES (SPREAD)\")\n",
    "print(\"-\"*80)\n",
    "print(\"\\n--- Bonferroni Corrected P-Values (Spread) ---\")\n",
    "print(p_values_corrected_df_spread_bonf.astype(float).round(4))\n",
    "print(\"\\n--- FDR Corrected P-Values (Spread) ---\")\n",
    "print(p_values_corrected_df_spread_fdr.astype(float).round(4))\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"COMPARISON OF CORRECTED P-VALUES (VOLUME)\")\n",
    "print(\"-\"*80)\n",
    "print(\"\\n--- Bonferroni Corrected P-Values (Volume) ---\")\n",
    "print(p_values_corrected_df_volume_bonf.astype(float).round(4))\n",
    "print(\"\\n--- FDR Corrected P-Values (Volume) ---\")\n",
    "print(p_values_corrected_df_volume_fdr.astype(float).round(4))\n",
    "\n",
    "# Figure 3A: Spread p-values with Bonferroni-corrected significance\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "sns.heatmap(p_values_spread_df, annot=True, cmap='viridis_r', fmt=\".3f\",\n",
    "            linewidths=.5, ax=ax, cbar_kws={'label': 'P-value (uncorrected)'})\n",
    "\n",
    "# Highlight Bonferroni-significant cells (This part remains unchanged)\n",
    "for i in range(len(p_values_corrected_df_spread_bonf.index)):\n",
    "    for j in range(len(p_values_corrected_df_spread_bonf.columns)):\n",
    "        val = p_values_corrected_df_spread_bonf.iloc[i, j]\n",
    "        if val < 0.05:\n",
    "            ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False,\n",
    "                                      edgecolor='red', lw=3))\n",
    "\n",
    "ax.set_title(f'Figure 3A: P-values for Spread (vs. Control) | {SPREAD_METHOD_NAME}\\nRed border = p < 0.05 (Bonferroni-corrected)',\n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/Figure_3A_PValues_Spread.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"\\nSaved: Figure_3A_PValues_Spread.png\")\n",
    "\n",
    "# Figure 3B: Volume p-values with Bonferroni-corrected significance\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "sns.heatmap(p_values_volume_df, annot=True, cmap='plasma_r', fmt=\".3f\",\n",
    "            linewidths=.5, ax=ax, cbar_kws={'label': 'P-value (uncorrected)'})\n",
    "\n",
    "# Highlight Bonferroni-significant cells (This part remains unchanged)\n",
    "for i in range(len(p_values_corrected_df_volume_bonf.index)):\n",
    "    for j in range(len(p_values_corrected_df_volume_bonf.columns)):\n",
    "        val = p_values_corrected_df_volume_bonf.iloc[i, j]\n",
    "        if val < 0.05:\n",
    "            ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False,\n",
    "                                      edgecolor='red', lw=3))\n",
    "\n",
    "ax.set_title(f'Figure 3B: P-values for Volume (vs. Control) | {SPREAD_METHOD_NAME}\\nRed border = p < 0.05 (Bonferroni-corrected)',\n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/Figure_3B_PValues_Volume.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: Figure_3B_PValues_Volume.png\")\n",
    "\n",
    "# FIGURE 4: HEATMAP - SPREAD BY CAP AND PERIOD\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"GENERATING FIGURE 4: HEATMAP\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "period_order = ['control_year', 'pre_easter', 'post_easter',\n",
    "                'pre_christmas', 'christmas', 'post_christmas',\n",
    "                'summer_excl_holiday', 'summer_holiday']\n",
    "period_order = [p for p in period_order if p in df['period_label'].unique()]\n",
    "\n",
    "heatmap_data = df.groupby(['Cap_Group', 'period_label'])['Spread'].mean().unstack()\n",
    "heatmap_data = heatmap_data[period_order]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "sns.heatmap(heatmap_data,\n",
    "            annot=True,\n",
    "            fmt='.5f',\n",
    "            cmap='YlOrRd',\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={'label': 'Avg Spread'},\n",
    "            ax=ax,\n",
    "            annot_kws={'fontsize': 11})\n",
    "\n",
    "ax.set_title(f'Figure 4: Average Spread by Cap Group and Period | {SPREAD_METHOD_NAME}',\n",
    "             fontweight='bold',\n",
    "             fontsize=18,\n",
    "             pad=15)\n",
    "\n",
    "ax.set_xlabel('Period', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Cap Group', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax.tick_params(axis='y', labelsize=13)\n",
    "ax.tick_params(axis='x', labelsize=12)\n",
    "\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/Figure_4_Heatmap_Spread.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: Figure_4_Heatmap_Spread.png\")\n",
    "\n",
    "# FIGURE 5: TIME SERIES - MONTHLY AVERAGE SPREAD\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(f\"GENERATING FIGURE 5: TIME SERIES | {SPREAD_METHOD_NAME}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "df['YearMonth'] = df['Date'].dt.to_period('M')\n",
    "monthly_spread = df.groupby('YearMonth')['Spread'].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "ax.plot(monthly_spread.index.to_timestamp(), monthly_spread.values,\n",
    "        color='darkblue', linewidth=1.5, alpha=0.8)\n",
    "ax.set_title(f'Figure 5: Monthly Average Spread (2014-2024) | {SPREAD_METHOD_NAME}', fontweight='bold', fontsize=16)\n",
    "ax.set_xlabel('Date', fontsize=14)\n",
    "ax.set_ylabel('Average Spread', fontsize=14)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "covid_start = pd.Timestamp('2020-03-01')\n",
    "covid_end = pd.Timestamp('2020-12-31')\n",
    "ax.axvspan(covid_start, covid_end, alpha=0.2, color='red', label='COVID-19')\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/Figure_5_Timeseries_Monthly.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Saved: Figure_5_Timeseries_Monthly.png\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"COMPLETE - 5 essential figures created\")\n",
    "print(\"-\"*80)\n",
    "print(\"\\nAll outputs saved to 'output/' folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f6bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT 3: OLS REGRESSION ANALYSIS WITH DYNAMIC DESCRIPTIVE TITLES\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"SCRIPT 3: OLS REGRESSION ANALYSIS\")\n",
    "# This will now work because SPREAD_METHOD_NAME was defined in a previous cell\n",
    "print(f\"Using Dependent Variable: {SPREAD_METHOD_NAME}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created directory: {output_dir}\")\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_CSV, parse_dates=['Date'])\n",
    "    print(f\"Successfully loaded data from {INPUT_CSV}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"FATAL ERROR: The input file '{INPUT_CSV}' was not found. Please ensure SCRIPT 1 has been run successfully.\")\n",
    "    exit()\n",
    "\n",
    "# Data Preparation\n",
    "print(\"\\n--- Preparing data for regression analysis ---\")\n",
    "df = df.sort_values(['Ticker', 'Date'])\n",
    "df['Return'] = df.groupby('Ticker')['Close'].pct_change()\n",
    "df['Volatility'] = df.groupby('Ticker')['Return'].transform(lambda x: x.shift(1).rolling(window=20, min_periods=10).std())\n",
    "df['Log_Volume'] = np.log1p(df['Volume'])\n",
    "df['Log_Volume_lag1'] = df.groupby('Ticker')['Log_Volume'].shift(1)\n",
    "\n",
    "# Holiday and Market Cap Dummies\n",
    "df['Pre_Easter'] = (df['period_label'] == 'pre_easter').astype(int)\n",
    "df['Post_Easter'] = (df['period_label'] == 'post_easter').astype(int)\n",
    "df['Christmas'] = (df['period_label'] == 'christmas').astype(int)\n",
    "df['Pre_Christmas'] = (df['period_label'] == 'pre_christmas').astype(int)\n",
    "df['Post_Christmas'] = (df['period_label'] == 'post_christmas').astype(int)\n",
    "df['Summer'] = (df['period_label'] == 'summer_holiday').astype(int)\n",
    "df['Large_Cap'] = (df['Cap_Group'] == 'Large Cap').astype(int)\n",
    "df['Mid_Cap'] = (df['Cap_Group'] == 'Mid Cap').astype(int)\n",
    "\n",
    "# Create regression sample\n",
    "df_reg = df.dropna(subset=['Spread', 'Log_Volume_lag1', 'Volatility']).copy()\n",
    "print(f\"Regression sample created with {len(df_reg):,} observations.\")\n",
    "\n",
    "# Models 1A-C: Baseline Holiday Effects by Market Cap\n",
    "print(\"\\n--- MODELS 1A-1C: BASELINE HOLIDAY EFFECTS BY MARKET CAP ---\")\n",
    "baseline_models = {}\n",
    "for i, cap in enumerate(['Large Cap', 'Mid Cap', 'Small Cap']):\n",
    "    print(f\"\\nProcessing Model 1{chr(65+i)}: {cap}\")\n",
    "    df_cap = df_reg[df_reg['Cap_Group'] == cap].copy()\n",
    "    \n",
    "    y = df_cap['Spread']\n",
    "    X = df_cap[['Pre_Easter', 'Post_Easter', 'Christmas', 'Pre_Christmas', 'Post_Christmas', 'Summer']]\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': df_cap['Ticker']})\n",
    "    baseline_models[cap] = model\n",
    "    \n",
    "    # Create and save summary as an image with the dynamic title\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    ax.axis('off')\n",
    "    title_text = f\"Table 1{chr(65+i)}: Baseline Spread Regression - {cap} Stocks\\nDependent Variable: {SPREAD_METHOD_NAME}\"\n",
    "    ax.text(0.5, 0.98, title_text, ha='center', va='top', fontsize=12, fontweight='bold', transform=ax.transAxes)\n",
    "    summary_text = str(model.summary())\n",
    "    ax.text(0.01, 0.93, summary_text, fontdict={'fontname': 'monospace', 'fontsize': 9}, va='top', ha='left', transform=ax.transAxes)\n",
    "    \n",
    "    filename = f\"output/Table_1{chr(65+i)}_Baseline_{cap.replace(' ', '_')}.png\"\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"SUCCESS: Saved model summary to {filename}\")\n",
    "\n",
    "# Model 2: Full Sample with Controls\n",
    "print(\"\\n--- MODEL 2: SPREAD WITH CONTROL VARIABLES ---\")\n",
    "X2 = df_reg[['Pre_Easter', 'Post_Easter', 'Christmas', 'Pre_Christmas', 'Post_Christmas', 'Summer',\n",
    "             'Log_Volume_lag1', 'Volatility', 'Large_Cap', 'Mid_Cap']]\n",
    "X2 = sm.add_constant(X2)\n",
    "y2 = df_reg['Spread']\n",
    "model2 = sm.OLS(y2, X2).fit(cov_type='cluster', cov_kwds={'groups': df_reg['Ticker']})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 11))\n",
    "ax.axis('off')\n",
    "title_text = (f'Table 2: Spread Determinants with Control Variables (Full Sample)\\n'\n",
    "              f'Dependent Variable: {SPREAD_METHOD_NAME} | Controls: Lagged Volume, Volatility, Market Cap')\n",
    "ax.text(0.5, 0.98, title_text, ha='center', va='top', fontsize=12, fontweight='bold', transform=ax.transAxes)\n",
    "summary_text = str(model2.summary())\n",
    "ax.text(0.01, 0.93, summary_text, fontdict={'fontname': 'monospace', 'fontsize': 9}, va='top', ha='left', transform=ax.transAxes)\n",
    "filename_2 = 'output/Table_2_Spread_Full_Controls.png'\n",
    "plt.savefig(filename_2, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"SUCCESS: Saved model summary to {filename_2}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Script finished. All regression tables have been saved as PNG images in the 'output' folder.\")\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef62776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT 4: ROBUSTNESS CHECK - EXCLUDE COVID PERIOD\n",
    "print(\"-\" * 80)\n",
    "print(\"SCRIPT 5: ROBUSTNESS CHECK - EXCLUDING COVID PERIOD\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Define the input file and output directory\n",
    "INPUT_CSV = \"oslo_bors_labelled_data.csv\"\n",
    "output_dir = 'output'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created directory: {output_dir}\")\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_CSV, parse_dates=['Date'])\n",
    "    print(f\"Successfully loaded data from '{INPUT_CSV}'\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"FATAL ERROR: The input file '{INPUT_CSV}' was not found. Please ensure it's in the correct directory.\")\n",
    "    exit() # Stop the script if the file doesn't exist\n",
    "\n",
    "# Exclude the COVID-19 Period\n",
    "print(\"\\n--- Excluding the entire year 2020 for robustness check ---\")\n",
    "df_robust = df[df['Date'].dt.year != 2020].copy()\n",
    "print(f\"Original sample size: {len(df):,} observations.\")\n",
    "print(f\"Robust sample size (2020 excluded): {len(df_robust):,} observations.\")\n",
    "print(f\"Removed {len(df) - len(df_robust):,} observations.\")\n",
    "\n",
    "# Step 2: Re-create all necessary variables\n",
    "print(\"\\n--- Re-creating analysis variables for the robust sample ---\")\n",
    "df_robust = df_robust.sort_values(['Ticker', 'Date'])\n",
    "df_robust['Return'] = df_robust.groupby('Ticker')['Close'].pct_change()\n",
    "df_robust['Volatility'] = df_robust.groupby('Ticker')['Return'].transform(lambda x: x.shift(1).rolling(window=20, min_periods=10).std())\n",
    "df_robust['Log_Volume'] = np.log1p(df_robust['Volume'])\n",
    "df_robust['Log_Volume_lag1'] = df_robust.groupby('Ticker')['Log_Volume'].shift(1)\n",
    "df_robust['Large_Cap'] = (df_robust['Cap_Group'] == 'Large Cap').astype(int)\n",
    "df_robust['Mid_Cap'] = (df_robust['Cap_Group'] == 'Mid Cap').astype(int)\n",
    "df_robust['Summer'] = (df_robust['period_label'] == 'summer_holiday').astype(int)\n",
    "df_robust['Christmas'] = (df_robust['period_label'] == 'christmas').astype(int)\n",
    "# Easter and other periods are intentionally excluded as per your original script's logic for the main models\n",
    "\n",
    "# Drop rows with missing values for the regression\n",
    "initial_len = len(df_robust)\n",
    "df_robust = df_robust.dropna(subset=['Spread', 'Log_Volume_lag1', 'Volatility']).copy()\n",
    "print(f\"Removed {initial_len - len(df_robust):,} rows with missing values needed for regression.\")\n",
    "print(f\"Final robust sample size: {len(df_robust):,} observations.\")\n",
    "\n",
    "# Step 3: Run the Single Robustness Regression Model\n",
    "print(\"\\n--- Running the main robustness regression model (OLS) ---\")\n",
    "\n",
    "# Define dependent and independent variables\n",
    "y = df_robust['Spread']\n",
    "X = df_robust[['Summer', 'Christmas', 'Log_Volume_lag1', 'Volatility', 'Large_Cap', 'Mid_Cap']]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model with clustered standard errors\n",
    "model_robust = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': df_robust['Ticker']})\n",
    "\n",
    "# Step 4: Save the Regression Output as a PNG Image\n",
    "print(\"\\n--- Saving the regression summary as a PNG image ---\")\n",
    "fig, ax = plt.subplots(figsize=(12, 11))\n",
    "ax.axis('off')\n",
    "\n",
    "# Set a descriptive title\n",
    "title_text = ('Table 5: Robustness Check - Excluding COVID-19 Period (2020)\\n'\n",
    "              f'Dependent Variable: {SPREAD_METHOD_NAME} | Controls: Lagged Volume, Volatility, Market Cap')\n",
    "ax.text(0.5, 0.98, title_text, ha='center', va='top', fontsize=12, fontweight='bold', transform=ax.transAxes)\n",
    "\n",
    "# Add the model summary text to the figure\n",
    "summary_text = str(model_robust.summary())\n",
    "ax.text(0.01, 0.93, summary_text, fontdict={'fontname': 'monospace', 'fontsize': 9}, va='top', ha='left', transform=ax.transAxes)\n",
    "\n",
    "# Define the output filename and save the figure\n",
    "output_filename_png = 'output/Table_5_Robustness_No_COVID.png'\n",
    "plt.savefig(output_filename_png, dpi=300, bbox_inches='tight')\n",
    "plt.close() # Close the figure to free up memory\n",
    "print(f\"SUCCESS: Regression summary saved to '{output_filename_png}'\")\n",
    "\n",
    "# Step 5: Create and Save a Coefficient Summary Table\n",
    "print(\"\\n--- Creating and saving a summary of key coefficients ---\")\n",
    "\n",
    "# Extract key coefficients into a DataFrame\n",
    "coef_table = pd.DataFrame({\n",
    "    'Variable': ['Summer', 'Christmas', 'Large_Cap', 'Mid_Cap'],\n",
    "    'Coefficient': model_robust.params[['Summer', 'Christmas', 'Large_Cap', 'Mid_Cap']],\n",
    "    'Std_Error': model_robust.bse[['Summer', 'Christmas', 'Large_Cap', 'Mid_Cap']],\n",
    "    'P_value': model_robust.pvalues[['Summer', 'Christmas', 'Large_Cap', 'Mid_Cap']]\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Add significance stars\n",
    "coef_table['Significance'] = coef_table['P_value'].apply(lambda x: '***' if x < 0.01 else ('**' if x < 0.05 else ('*' if x < 0.1 else '')))\n",
    "print(\"\\nKey Coefficients (Robust Sample):\")\n",
    "print(coef_table.to_string(index=False))\n",
    "\n",
    "# Save the coefficient table to a CSV file\n",
    "output_filename_csv = 'output/Robustness_Coefficients_Summary.csv'\n",
    "coef_table.to_csv(output_filename_csv, index=False)\n",
    "print(f\"\\nSUCCESS: Coefficient summary saved to '{output_filename_csv}'\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ROBUSTNESS CHECK SCRIPT COMPLETE\")\n",
    "print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
